{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import random\n",
    "import collections\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elapsed(sec):\n",
    "    if sec<60:\n",
    "        return str(sec) + ' sec'\n",
    "    elif sec<3600:\n",
    "        return str(sec/60) + ' min'\n",
    "    else:\n",
    "        return str(sec/3600) + ' hr'\n",
    "    \n",
    "def read_data(fname):\n",
    "    with open(fname) as f:\n",
    "        content = f.readlines()\n",
    "        content = [x.strip() for x in content]\n",
    "        content = [content[i].split() for i in range(len(content))]\n",
    "        content = np.array(content)\n",
    "        content = np.reshape(content, [-1, ])\n",
    "    return content\n",
    "\n",
    "def build_dataset(words):\n",
    "    count = collections.Counter(words).most_common()\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "        reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return dictionary, reverse_dictionary\n",
    "\n",
    "trainingFile = 'train.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded training data...\n",
      "[list(['on', 'a', 'mango', 'tree', 'in', 'a', 'jungle', ',', 'there', 'lived', 'many', 'birds', '.', 'they', 'were', 'happy', 'in', 'their', 'small'])\n",
      " list(['nests', '.', 'before', 'the', 'onset', 'of', 'the', 'rainy', 'season', ',', 'all', 'the', 'animals', 'of', 'the', 'jungle', 'repaired', 'their', 'homes'])\n",
      " list(['.', 'the', 'birds', 'also', 'made', 'their', 'homes', 'more', 'secure', '.', 'many', 'birds', 'brought', 'twigs', 'and', 'leaves', 'and'])\n",
      " list(['others', 'wove', 'their', 'nests', '.', 'we', 'should', 'also', 'store', 'some', 'food', 'for', 'our', 'children', ',', 'chirped', 'one', 'of', 'the'])\n",
      " list(['birds', '.', 'and', 'they', 'collected', 'food', ',', 'until', 'they', 'had', 'enough', 'to', 'see', 'them', 'through', 'the', 'rainy', 'season', '.'])\n",
      " list(['they', 'kept', 'themselves', 'busy', 'preparing', 'for', 'the', 'tough', 'times', '.', 'soon', 'the', 'rains', 'came', '.', 'it', 'was', 'followed'])\n",
      " list(['by', 'thunder', 'and', 'lighting', '.', 'all', 'the', 'animals', 'and', 'birds', 'stayed', 'in', 'their', 'homes', '.', 'it', 'continued', 'raining'])\n",
      " list(['for', 'many', 'days', '.', 'one', 'day', ',', 'a', 'monkey', 'went', 'in', 'the', 'rain', 'came', 'into', 'the', 'forest', '.', 'he', 'sat', 'on', 'a', 'branch'])\n",
      " list([',', 'shivering', 'with', 'cold', ',', 'water', 'dripping', 'from', 'its', 'body', '.', 'the', 'poor', 'monkey', 'tried', 'his', 'best', 'to', 'get', 'shelter'])\n",
      " list([',', 'but', 'in', 'vain', '.', 'the', 'leaves', 'were', 'not', 'enough', 'to', 'save', 'him', 'from', 'the', 'rains', '.', 'it', 'is', 'so', 'cold', ',', 'said', 'the'])\n",
      " list(['monkey', '.', 'the', 'birds', 'were', 'watching', 'all', 'this', '.', 'they', 'felt', 'sorry', 'for', 'the', 'monkey', 'but', 'there', 'was', 'little'])\n",
      " list(['they', 'could', 'do', 'for', 'him', '.', 'one', 'of', 'them', 'said', ',', 'brother', ',', 'our', 'small', 'nests', 'are', 'not', 'enough', 'to', 'give', 'you'])\n",
      " list(['shelter', '.', 'another', 'bird', 'said', ',', 'all', 'of', 'us', 'prepared', 'for', 'the', 'rainy', 'season', '.', 'if', 'you', 'had', ',', 'you', 'would', 'not'])\n",
      " list(['be', 'in', 'this', 'situation', '.', 'how', 'dare', 'you', 'tell', 'me', 'what', 'to', 'do', ',', 'said', 'the', 'monkey', ',', 'growling', 'at', 'the', 'bird', '.'])\n",
      " list(['the', 'monkey', 'angrily', 'pounced', 'on', 'the', 'birds', 'nest', ',', 'tore', 'it', 'and', 'threw', 'it', 'on', 'the', 'ground', '.', 'the', 'bird'])\n",
      " list(['and', 'her', 'chicks', 'were', 'helpless', '.', 'the', 'poor', 'bird', 'thought', ',', 'fools', 'never', 'value', 'good', 'advice', '.', 'it', 'is'])]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-455761a83ecf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loaded training data...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse_dictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mvocabSize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-ec567c32d356>\u001b[0m in \u001b[0;36mbuild_dataset\u001b[0;34m(words)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mdictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/collections/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'expected at most 1 arguments, got %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__missing__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/collections/__init__.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    615\u001b[0m                     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# fast path when counter is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m                 \u001b[0m_count_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "trainData = read_data(trainingFile)\n",
    "print('Loaded training data...')\n",
    "print((trainData))\n",
    "dictionary, reverse_dictionary = build_dataset(trainData)\n",
    "vocabSize = len(dictionary)\n",
    "print(dictionary)\n",
    "\n",
    "learnRate = 0.001\n",
    "nrEpochs = 30000\n",
    "displayStep = 1000\n",
    "sequenceLength = 3\n",
    "hiddenSize = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
