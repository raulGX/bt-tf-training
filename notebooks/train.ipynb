{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This script will train the MobileNet model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import hashlib\n",
    "import os.path\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "import tarfile\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import urllib\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "from tensorflow.python.platform import gfile\n",
    "from tensorflow.python.util import compat\n",
    "\n",
    "\n",
    "# These are all parameters that are tied to the particular model architecture\n",
    "# we're using for Inception v3. These include things like tensor names and their\n",
    "# sizes. If you want to adapt this script to work with another model, you will\n",
    "# need to update these to reflect the values in the network you're using.\n",
    "MAX_NUM_IMAGES_PER_CLASS = 2 ** 27 - 1  # ~134M\n",
    "\n",
    "# The location where variable checkpoints will be stored.\n",
    "CHECKPOINT_NAME = '/tmp/_retrain_checkpoint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = argparse.Namespace(architecture='mobilenet_1.0_224', \n",
    "             bottleneck_dir='/tmp/bottleneck', \n",
    "             eval_step_interval=100,\n",
    "             final_tensor_name='final_result', \n",
    "             flip_left_right=True, \n",
    "             how_many_training_steps=600,\n",
    "             image_dir='data/', \n",
    "             intermediate_output_graphs_dir='/tmp/intermediate_graph/', \n",
    "             intermediate_store_frequency=0,\n",
    "             learning_rate=0.0001, model_dir='/tmp/imagenet', \n",
    "             output_graph='/tmp/output_graph.pb',\n",
    "             output_labels='/tmp/output_labels.txt', \n",
    "             print_misclassified_test_images=False, \n",
    "             random_brightness=30,\n",
    "             random_crop=0, \n",
    "             random_scale=30, \n",
    "             saved_model_dir='/tmp/saved_models/1/',\n",
    "             summaries_dir='/tmp/retrain_logs', \n",
    "             test_batch_size=-1, \n",
    "             testing_percentage=10, \n",
    "             train_batch_size=32,\n",
    "             validation_batch_size=-1, \n",
    "             validation_percentage=10)\n",
    "\n",
    "from scripts.retrain import *\n",
    "set_flags(FLAGS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed to make sure the logging output is visible.\n",
    "# See https://github.com/tensorflow/tensorflow/issues/3047\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# Prepare necessary directories that can be used during training\n",
    "prepare_file_system()\n",
    "\n",
    "# Gather information about the model architecture we'll be using.\n",
    "model_info = create_model_info(FLAGS.architecture)\n",
    "\n",
    "if not model_info:\n",
    "  tf.logging.error('Did not recognize architecture flag')\n",
    "  raise Exception('Error')\n",
    "\n",
    "# Look at the folder structure, and create lists of all the images.\n",
    "image_lists = create_image_lists(FLAGS.image_dir, FLAGS.testing_percentage,\n",
    "                                 FLAGS.validation_percentage)\n",
    "class_count = len(image_lists.keys())\n",
    "if class_count == 0:\n",
    "  tf.logging.error('No valid folders of images found at ' + FLAGS.image_dir)\n",
    "  raise Exception('Error')\n",
    "if class_count == 1:\n",
    "  tf.logging.error('Only one valid folder of images found at ' +\n",
    "                   FLAGS.image_dir +\n",
    "                   ' - multiple classes are needed for classification.')\n",
    "\n",
    "# See if the command-line flags mean we're applying any distortions.\n",
    "do_distort_images = should_distort_images(\n",
    "    FLAGS.flip_left_right, FLAGS.random_crop, FLAGS.random_scale,\n",
    "    FLAGS.random_brightness)\n",
    "\n",
    "# Set up the pre-trained graph.\n",
    "maybe_download_and_extract(model_info['data_url'])\n",
    "graph, bottleneck_tensor, resized_image_tensor = (\n",
    "    create_model_graph(model_info))\n",
    "\n",
    "# Add the new layer that we'll be training.\n",
    "with graph.as_default():\n",
    "  (train_step, cross_entropy, bottleneck_input,\n",
    "   ground_truth_input, final_tensor) = add_final_retrain_ops(\n",
    "       class_count, FLAGS.final_tensor_name, bottleneck_tensor,\n",
    "       model_info['bottleneck_tensor_size'], model_info['quantize_layer'],\n",
    "       True)\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "  # Set up the image decoding sub-graph.\n",
    "  jpeg_data_tensor, decoded_image_tensor = add_jpeg_decoding(\n",
    "      model_info['input_width'], model_info['input_height'],\n",
    "      model_info['input_depth'], model_info['input_mean'],\n",
    "      model_info['input_std'])\n",
    "\n",
    "  if do_distort_images:\n",
    "    # We will be applying distortions, so setup the operations we'll need.\n",
    "    (distorted_jpeg_data_tensor,\n",
    "     distorted_image_tensor) = add_input_distortions(\n",
    "         FLAGS.flip_left_right, FLAGS.random_crop, FLAGS.random_scale,\n",
    "         FLAGS.random_brightness, model_info['input_width'],\n",
    "         model_info['input_height'], model_info['input_depth'],\n",
    "         model_info['input_mean'], model_info['input_std'])\n",
    "  else:\n",
    "    # We'll make sure we've calculated the 'bottleneck' image summaries and\n",
    "    # cached them on disk.\n",
    "    cache_bottlenecks(sess, image_lists, FLAGS.image_dir,\n",
    "                      FLAGS.bottleneck_dir, jpeg_data_tensor,\n",
    "                      decoded_image_tensor, resized_image_tensor,\n",
    "                      bottleneck_tensor, FLAGS.architecture)\n",
    "\n",
    "  # Create the operations we need to evaluate the accuracy of our new layer.\n",
    "  evaluation_step, _ = add_evaluation_step(final_tensor, ground_truth_input)\n",
    "\n",
    "  # Merge all the summaries and write them out to the summaries_dir\n",
    "  merged = tf.summary.merge_all()\n",
    "  train_writer = tf.summary.FileWriter(FLAGS.summaries_dir + '/train',\n",
    "                                       sess.graph)\n",
    "\n",
    "  validation_writer = tf.summary.FileWriter(\n",
    "      FLAGS.summaries_dir + '/validation')\n",
    "\n",
    "  # Create a train saver that is used to restore values into an eval graph\n",
    "  # when exporting models.\n",
    "  train_saver = tf.train.Saver()\n",
    "\n",
    "  # Set up all our weights to their initial default values.\n",
    "  init = tf.global_variables_initializer()\n",
    "  sess.run(init)\n",
    "\n",
    "  # Run the training for as many cycles as requested on the command line.\n",
    "  for i in range(FLAGS.how_many_training_steps):\n",
    "    # Get a batch of input bottleneck values, either calculated fresh every\n",
    "    # time with distortions applied, or from the cache stored on disk.\n",
    "    if do_distort_images:\n",
    "      (train_bottlenecks,\n",
    "       train_ground_truth) = get_random_distorted_bottlenecks(\n",
    "           sess, image_lists, FLAGS.train_batch_size, 'training',\n",
    "           FLAGS.image_dir, distorted_jpeg_data_tensor,\n",
    "           distorted_image_tensor, resized_image_tensor, bottleneck_tensor)\n",
    "    else:\n",
    "      (train_bottlenecks,\n",
    "       train_ground_truth, _) = get_random_cached_bottlenecks(\n",
    "           sess, image_lists, FLAGS.train_batch_size, 'training',\n",
    "           FLAGS.bottleneck_dir, FLAGS.image_dir, jpeg_data_tensor,\n",
    "           decoded_image_tensor, resized_image_tensor, bottleneck_tensor,\n",
    "           FLAGS.architecture)\n",
    "    # Feed the bottlenecks and ground truth into the graph, and run a training\n",
    "    # step. Capture training summaries for TensorBoard with the `merged` op.\n",
    "    train_summary, _ = sess.run(\n",
    "        [merged, train_step],\n",
    "        feed_dict={bottleneck_input: train_bottlenecks,\n",
    "                   ground_truth_input: train_ground_truth})\n",
    "    train_writer.add_summary(train_summary, i)\n",
    "\n",
    "    # Every so often, print out how well the graph is training.\n",
    "    is_last_step = (i + 1 == FLAGS.how_many_training_steps)\n",
    "    if (i % FLAGS.eval_step_interval) == 0 or is_last_step:\n",
    "      train_accuracy, cross_entropy_value = sess.run(\n",
    "          [evaluation_step, cross_entropy],\n",
    "          feed_dict={bottleneck_input: train_bottlenecks,\n",
    "                     ground_truth_input: train_ground_truth})\n",
    "      tf.logging.info('%s: Step %d: Train accuracy = %.1f%%' %\n",
    "                      (datetime.now(), i, train_accuracy * 100))\n",
    "      tf.logging.info('%s: Step %d: Cross entropy = %f' %\n",
    "                      (datetime.now(), i, cross_entropy_value))\n",
    "      # TODO(suharshs): Make this use an eval graph, to avoid quantization\n",
    "      # moving averages being updated by the validation set, though in\n",
    "      # practice this makes a negligable difference.\n",
    "      validation_bottlenecks, validation_ground_truth, _ = (\n",
    "          get_random_cached_bottlenecks(\n",
    "              sess, image_lists, FLAGS.validation_batch_size, 'validation',\n",
    "              FLAGS.bottleneck_dir, FLAGS.image_dir, jpeg_data_tensor,\n",
    "              decoded_image_tensor, resized_image_tensor, bottleneck_tensor,\n",
    "              FLAGS.architecture))\n",
    "      # Run a validation step and capture training summaries for TensorBoard\n",
    "      # with the `merged` op.\n",
    "      validation_summary, validation_accuracy = sess.run(\n",
    "          [merged, evaluation_step],\n",
    "          feed_dict={bottleneck_input: validation_bottlenecks,\n",
    "                     ground_truth_input: validation_ground_truth})\n",
    "      validation_writer.add_summary(validation_summary, i)\n",
    "      tf.logging.info('%s: Step %d: Validation accuracy = %.1f%% (N=%d)' %\n",
    "                      (datetime.now(), i, validation_accuracy * 100,\n",
    "                       len(validation_bottlenecks)))\n",
    "\n",
    "    # Store intermediate results\n",
    "    intermediate_frequency = FLAGS.intermediate_store_frequency\n",
    "\n",
    "    if (intermediate_frequency > 0 and (i % intermediate_frequency == 0)\n",
    "        and i > 0):\n",
    "      # If we want to do an intermediate save, save a checkpoint of the train\n",
    "      # graph, to restore into the eval graph.\n",
    "      train_saver.save(sess, CHECKPOINT_NAME)\n",
    "      intermediate_file_name = (FLAGS.intermediate_output_graphs_dir +\n",
    "                                'intermediate_' + str(i) + '.pb')\n",
    "      tf.logging.info('Save intermediate result to : ' +\n",
    "                      intermediate_file_name)\n",
    "      save_graph_to_file(graph, intermediate_file_name, model_info,\n",
    "                         class_count)\n",
    "\n",
    "  # After training is complete, force one last save of the train checkpoint.\n",
    "  train_saver.save(sess, CHECKPOINT_NAME)\n",
    "\n",
    "  # We've completed all our training, so run a final test evaluation on\n",
    "  # some new images we haven't used before.\n",
    "  run_final_eval(sess, model_info, class_count, image_lists, jpeg_data_tensor,\n",
    "                 decoded_image_tensor, resized_image_tensor,\n",
    "                 bottleneck_tensor)\n",
    "\n",
    "  # Write out the trained graph and labels with the weights stored as\n",
    "  # constants.\n",
    "  save_graph_to_file(graph, FLAGS.output_graph, model_info, class_count)\n",
    "  with gfile.FastGFile(FLAGS.output_labels, 'w') as f:\n",
    "    f.write('\\n'.join(image_lists.keys()) + '\\n')\n",
    "\n",
    "  export_model(model_info, class_count, FLAGS.saved_model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
